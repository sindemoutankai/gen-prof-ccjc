{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c42d9d7-5d11-42c3-ba18-3060046709d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWarning:\u001b[0m mecab 0.996 is already installed and up-to-date.\n",
      "To reinstall 0.996, run:\n",
      "  brew reinstall mecab\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/mecab-ipadic/manifests/2.7.0-20\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[32m==>\u001b[0m \u001b[1mFetching \u001b[32mmecab-ipadic\u001b[39m\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mDownloading https://ghcr.io/v2/homebrew/core/mecab-ipadic/blobs/sha256:fd420\u001b[0m\n",
      "######################################################################### 100.0%\n",
      "\u001b[34m==>\u001b[0m \u001b[1mPouring mecab-ipadic--2.7.0-20070801.ventura.bottle.tar.gz\u001b[0m\n",
      "\u001b[34m==>\u001b[0m \u001b[1mCaveats\u001b[0m\n",
      "To enable mecab-ipadic dictionary, add to /usr/local/etc/mecabrc:\n",
      "  dicdir = /usr/local/lib/mecab/dic/ipadic\n",
      "\u001b[34m==>\u001b[0m \u001b[1mSummary\u001b[0m\n",
      "ğŸº  /usr/local/Cellar/mecab-ipadic/2.7.0-20070801: 14 files, 50.6MB\n",
      "\u001b[34m==>\u001b[0m \u001b[1mRunning `brew cleanup mecab-ipadic`...\u001b[0m\n",
      "Disable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\n",
      "Hide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n"
     ]
    }
   ],
   "source": [
    "!brew install mecab\n",
    "!brew install mecab-ipadic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eff4c175-81ad-4958-addc-87830fed8024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mecab-python3\n",
      "  Downloading mecab_python3-1.0.8-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.1 kB)\n",
      "Downloading mecab_python3-1.0.8-cp311-cp311-macosx_10_9_x86_64.whl (513 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m513.1/513.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mecab-python3\n",
      "Successfully installed mecab-python3-1.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mecab-python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a98617a4-c9d7-4412-b9ca-c50c9e7f7931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã“ã‚“ã«ã¡ã¯\tæ„Ÿå‹•è©,*,*,*,*,*,ã“ã‚“ã«ã¡ã¯,ã‚³ãƒ³ãƒ‹ãƒãƒ,ã‚³ãƒ³ãƒ‹ãƒãƒ¯\n",
      "ã€\tè¨˜å·,èª­ç‚¹,*,*,*,*,ã€,ã€,ã€\n",
      "ä¸–ç•Œ\tåè©,ä¸€èˆ¬,*,*,*,*,ä¸–ç•Œ,ã‚»ã‚«ã‚¤,ã‚»ã‚«ã‚¤\n",
      "ï¼\tè¨˜å·,ä¸€èˆ¬,*,*,*,*,ï¼,ï¼,ï¼\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import MeCab\n",
    "\n",
    "mecab = MeCab.Tagger()\n",
    "result = mecab.parse(\"ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œï¼\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e3a9d-8823-47fa-9d55-e0623c32c29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d56fb0-1a6d-48a0-891d-d5d68b89db31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import MeCab\n",
    "\n",
    "\n",
    "class Checker:\n",
    "    def __init__(self, ng_words_file='assets/input/ngword_list.csv'):\n",
    "        #self.xml_text = xml_text\n",
    "        self.ng_words_file = ng_words_file\n",
    "        self.mecab = MeCab.Tagger()\n",
    "\n",
    "    def xml_checker(self, xml_text):\n",
    "        try:\n",
    "            root = ET.fromstring(xml_text)\n",
    "\n",
    "            if root.tag != 'profile':\n",
    "                return False\n",
    "\n",
    "            expected_tags = {\n",
    "                'hashtags', 'big_five_chart', 'character', 'personality',\n",
    "                'hometown'\n",
    "            }\n",
    "\n",
    "            for child in root:\n",
    "                if child.tag not in expected_tags:\n",
    "                    return False\n",
    "                if child.tag == 'big_five_chart':\n",
    "                    expected_subtags = {'openness', 'conscientiousness',\n",
    "                                        'extraversion', 'agreeableness', 'neuroticism'}\n",
    "                    for subchild in child:\n",
    "                        if subchild.tag not in expected_subtags:\n",
    "                            return False\n",
    "\n",
    "            return True\n",
    "        except ET.ParseError:\n",
    "            return False\n",
    "\n",
    "    def xml_checker2(self, xml_text):\n",
    "        try:\n",
    "            root = ET.fromstring(xml_text)\n",
    "\n",
    "            if root.tag != 'profile':\n",
    "                return False\n",
    "\n",
    "            expected_tags = {\n",
    "                'occupation', 'favorite_things', 'hobby',\n",
    "                'skill', 'habit', 'dream', 'talent', 'motto', 'comment'\n",
    "            }\n",
    "\n",
    "            # XMLå†…ã®ã‚¿ã‚°é›†ã‚ã‚‹\n",
    "            found_tags = {child.tag for child in root}\n",
    "\n",
    "            # æœŸå¾…ã•ã‚Œã‚‹ã™ã¹ã¦ã®ã‚¿ã‚°ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "            if not expected_tags.issubset(found_tags):\n",
    "                return False\n",
    "\n",
    "            for child in root:\n",
    "                if len(child.text or '') > 30:\n",
    "                    return False\n",
    "\n",
    "            return True\n",
    "        except ET.ParseError:\n",
    "            return False\n",
    "\n",
    "\n",
    "#ã“ã“ã‹ã‚‰å¤‰æ›å‡¦ç†\n",
    "    def _full_to_half(self, text):\n",
    "\n",
    "        full_to_half_map = str.maketrans(\n",
    "            'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šã€€'\n",
    "            'ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ãƒ˜ãƒ›ãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ¯ãƒ²ãƒ³ã‚¡ã‚£ã‚¥ã‚§ã‚©ãƒ£ãƒ¥ãƒ§ãƒƒãƒ¼',\n",
    "            '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz '\n",
    "            'ï½±ï½²ï½³ï½´ï½µï½¶ï½·ï½¸ï½¹ï½ºï½»ï½¼ï½½ï½¾ï½¿ï¾€ï¾ï¾‚ï¾ƒï¾„ï¾…ï¾†ï¾‡ï¾ˆï¾‰ï¾Šï¾‹ï¾Œï¾ï¾ï¾ï¾ï¾‘ï¾’ï¾“ï¾”ï¾•ï¾–ï¾—ï¾˜ï¾™ï¾šï¾›ï¾œï½¦ï¾ï½§ï½¨ï½©ï½ªï½«ï½¬ï½­ï½®ï½¯ï½°')\n",
    "        text = text.translate(full_to_half_map)\n",
    "\n",
    "        dakuten_chars = {\n",
    "            'ã‚¬': 'ï½¶ï¾', 'ã‚®': 'ï½·ï¾', 'ã‚°': 'ï½¸ï¾', 'ã‚²': 'ï½¹ï¾', 'ã‚´': 'ï½ºï¾',\n",
    "            'ã‚¶': 'ï½»ï¾', 'ã‚¸': 'ï½¼ï¾', 'ã‚º': 'ï½½ï¾', 'ã‚¼': 'ï½¾ï¾', 'ã‚¾': 'ï½¿ï¾',\n",
    "            'ãƒ€': 'ï¾€ï¾', 'ãƒ‚': 'ï¾ï¾', 'ãƒ…': 'ï¾‚ï¾', 'ãƒ‡': 'ï¾ƒï¾', 'ãƒ‰': 'ï¾„ï¾',\n",
    "            'ãƒ': 'ï¾Šï¾', 'ãƒ“': 'ï¾‹ï¾', 'ãƒ–': 'ï¾Œï¾', 'ãƒ™': 'ï¾ï¾', 'ãƒœ': 'ï¾ï¾',\n",
    "            'ãƒ‘': 'ï¾Šï¾Ÿ', 'ãƒ”': 'ï¾‹ï¾Ÿ', 'ãƒ—': 'ï¾Œï¾Ÿ', 'ãƒš': 'ï¾ï¾Ÿ', 'ãƒ': 'ï¾ï¾Ÿ',\n",
    "            'ãƒ´': 'ï½³ï¾'\n",
    "        }\n",
    "        for full, half in dakuten_chars.items():\n",
    "            text = text.replace(full, half)\n",
    "        return text\n",
    "\n",
    "    def _half_to_full(self, text):\n",
    "\n",
    "        half_to_full_map = str.maketrans(\n",
    "            '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz '\n",
    "            'ï½±ï½²ï½³ï½´ï½µï½¶ï½·ï½¸ï½¹ï½ºï½»ï½¼ï½½ï½¾ï½¿ï¾€ï¾ï¾‚ï¾ƒï¾„ï¾…ï¾†ï¾‡ï¾ˆï¾‰ï¾Šï¾‹ï¾Œï¾ï¾ï¾ï¾ï¾‘ï¾’ï¾“ï¾”ï¾•ï¾–ï¾—ï¾˜ï¾™ï¾šï¾›ï¾œï½¦ï¾ï½§ï½¨ï½©ï½ªï½«ï½¬ï½­ï½®ï½¯ï½°',\n",
    "            'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™ï¼¡ï¼¢ï¼£ï¼¤ï¼¥ï¼¦ï¼§ï¼¨ï¼©ï¼ªï¼«ï¼¬ï¼­ï¼®ï¼¯ï¼°ï¼±ï¼²ï¼³ï¼´ï¼µï¼¶ï¼·ï¼¸ï¼¹ï¼ºï½ï½‚ï½ƒï½„ï½…ï½†ï½‡ï½ˆï½‰ï½Šï½‹ï½Œï½ï½ï½ï½ï½‘ï½’ï½“ï½”ï½•ï½–ï½—ï½˜ï½™ï½šã€€'\n",
    "            'ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ãƒ˜ãƒ›ãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ¯ãƒ²ãƒ³ã‚¡ã‚£ã‚¥ã‚§ã‚©ãƒ£ãƒ¥ãƒ§ãƒƒãƒ¼')\n",
    "        text = text.translate(half_to_full_map)\n",
    "\n",
    "        # æ¿ç‚¹ä»˜ãã€åŠæ¿ç‚¹ä»˜ãã‚«ã‚¿ã‚«ãƒŠã®åŠè§’ã‚’å…¨è§’ã«å¤‰æ›\n",
    "        handakuten_chars = {\n",
    "            'ï½¶ï¾': 'ã‚¬', 'ï½·ï¾': 'ã‚®', 'ï½¸ï¾': 'ã‚°', 'ï½¹ï¾': 'ã‚²', 'ï½ºï¾': 'ã‚´',\n",
    "            'ï½»ï¾': 'ã‚¶', 'ï½¼ï¾': 'ã‚¸', 'ï½½ï¾': 'ã‚º', 'ï½¾ï¾': 'ã‚¼', 'ï½¿ï¾': 'ã‚¾',\n",
    "            'ï¾€ï¾': 'ãƒ€', 'ï¾ï¾': 'ãƒ‚', 'ï¾‚ï¾': 'ãƒ…', 'ï¾ƒï¾': 'ãƒ‡', 'ï¾„ï¾': 'ãƒ‰',\n",
    "            'ï¾Šï¾': 'ãƒ', 'ï¾‹ï¾': 'ãƒ“', 'ï¾Œï¾': 'ãƒ–', 'ï¾ï¾': 'ãƒ™', 'ï¾ï¾': 'ãƒœ',\n",
    "            'ï¾Šï¾Ÿ': 'ãƒ‘', 'ï¾‹ï¾Ÿ': 'ãƒ”', 'ï¾Œï¾Ÿ': 'ãƒ—', 'ï¾ï¾Ÿ': 'ãƒš', 'ï¾ï¾Ÿ': 'ãƒ',\n",
    "            'ï½³ï¾': 'ãƒ´'\n",
    "        }\n",
    "        for half, full in handakuten_chars.items():\n",
    "            text = text.replace(half, full)\n",
    "        return text\n",
    "\n",
    "    def detect_ng_word(self, xml_text):\n",
    "        # åŠè§’ã‚«ã‚¿ã‚«ãƒŠã‚’å…¨è§’ã«å¤‰æ›\n",
    "        xml_text = self._half_to_full(xml_text)\n",
    "\n",
    "        with open(self.ng_words_file, 'r') as file:\n",
    "            ng_words = {line.strip() for line in file}\n",
    "\n",
    "        node = self.mecab.parseToNode(xml_text)\n",
    "        while node:\n",
    "            word = node.surface\n",
    "            if word in ng_words:\n",
    "                print(word)\n",
    "                return False\n",
    "            node = node.next\n",
    "        return True\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b77a45d8-f972-4da6-8dd8-744708d3ee56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã‚¸ãƒ¥ãƒ¼ã‚¹\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "checker = Checker()\n",
    "\n",
    "# NGãƒ¯ãƒ¼ãƒ‰æ¤œå‡º\n",
    "ng_word_result = checker.detect_ng_word('ï¼ƒã‚¸ãƒ¥ãƒ¼ã‚¹ã€€ï¼ƒãƒ©ãƒ³ãƒå¤§å¥½ãã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚ã‚')\n",
    "print(ng_word_result)\n",
    "# XMLãƒã‚§ãƒƒã‚«ãƒ¼ã®ä½¿ç”¨\n",
    "xml_checker_result = checker.xml_checker('<profile><hobby>ãƒ†ãƒ‹ã‚¹ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†ã†</hobby></profile>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6309d2ed-6456-4220-b6d1-2374a91a2ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26166ba-3f83-4026-a122-88cbd01c830c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
